# This file was autogenerated by uv via the following command:
#    uv export --no-hashes
-e .
absl-py==2.3.1
    # via ml-collections
adapters==1.2.0
    # via wtpsplit
aiohappyeyeballs==2.6.1
    # via aiohttp
aiohttp==3.12.15
    # via fsspec
aiosignal==1.4.0
    # via aiohttp
annotated-types==0.7.0
    # via pydantic
antlr4-python3-runtime==4.9.3
    # via omegaconf
anyio==4.10.0
    # via
    #   httpx
    #   openai
astroid==3.3.11
    # via pylint
async-timeout==5.0.1 ; python_full_version < '3.11'
    # via aiohttp
attrs==25.3.0
    # via aiohttp
audio-separator==0.40.0
    # via verbatim
audioread==3.0.1
    # via librosa
av==15.0.0
    # via
    #   faster-whisper
    #   verbatim
beartype==0.18.5
    # via audio-separator
cached-property==2.0.1
    # via wtpsplit
certifi==2025.8.3
    # via
    #   httpcore
    #   httpx
    #   requests
cffi==1.17.1
    # via
    #   samplerate
    #   sounddevice
    #   soundfile
charset-normalizer==3.4.3
    # via requests
cloudpickle==3.1.1
    # via submitit
colorama==0.4.6
    # via
    #   pylint
    #   pytest
    #   tqdm
    #   verbatim
coloredlogs==15.0.1
    # via onnxruntime
ctranslate2==4.6.0
    # via faster-whisper
cython==3.1.3
    # via
    #   diffq
    #   diffq-fixed
dataclasses-json==0.6.7
    # via verbatim
datasets==4.0.0
    # via verbatim
decorator==5.2.1
    # via librosa
demucs==4.0.1
    # via verbatim
diffq==0.2.4 ; sys_platform != 'win32'
    # via audio-separator
diffq-fixed==0.2.4 ; sys_platform == 'win32'
    # via audio-separator
dill==0.3.8
    # via
    #   datasets
    #   multiprocess
    #   pylint
distro==1.9.0
    # via openai
docopt==0.6.2
    # via mosestokenizer
dora-search==0.1.12
    # via demucs
einops==0.8.1
    # via
    #   audio-separator
    #   demucs
    #   rotary-embedding-torch
exceptiongroup==1.3.0 ; python_full_version < '3.11'
    # via
    #   anyio
    #   pytest
faster-whisper==1.2.0
    # via verbatim
filelock==3.19.1
    # via
    #   datasets
    #   huggingface-hub
    #   torch
    #   transformers
flatbuffers==25.2.10
    # via onnxruntime
frozenlist==1.7.0
    # via
    #   aiohttp
    #   aiosignal
fsspec==2025.3.0
    # via
    #   datasets
    #   huggingface-hub
    #   torch
h11==0.16.0
    # via httpcore
hf-xet==1.1.9 ; platform_machine == 'aarch64' or platform_machine == 'amd64' or platform_machine == 'arm64' or platform_machine == 'x86_64'
    # via huggingface-hub
httpcore==1.0.9
    # via httpx
httpx==0.28.1
    # via openai
huggingface-hub==0.34.4
    # via
    #   datasets
    #   faster-whisper
    #   mlx-whisper
    #   speechbrain
    #   tokenizers
    #   transformers
    #   wtpsplit
humanfriendly==10.0
    # via coloredlogs
hyperpyyaml==1.2.2
    # via speechbrain
idna==3.10
    # via
    #   anyio
    #   httpx
    #   requests
    #   yarl
iniconfig==2.1.0
    # via pytest
isort==6.0.1
    # via pylint
jinja2==3.1.6
    # via torch
jiter==0.10.0
    # via openai
joblib==1.5.2
    # via
    #   librosa
    #   scikit-learn
    #   speechbrain
julius==0.2.7
    # via
    #   audio-separator
    #   demucs
lameenc==1.8.1
    # via demucs
langcodes==3.5.0
    # via verbatim
language-data==1.3.0
    # via langcodes
lazy-loader==0.4
    # via librosa
librosa==0.11.0
    # via audio-separator
llvmlite==0.45.1
    # via numba
lxml==6.0.1
    # via python-docx
marisa-trie==1.3.1
    # via language-data
markupsafe==3.0.2
    # via jinja2
marshmallow==3.26.1
    # via dataclasses-json
mccabe==0.7.0
    # via pylint
ml-collections==1.1.0
    # via audio-separator
ml-dtypes==0.5.3
    # via onnx-weekly
mlx==0.29.0 ; sys_platform == 'darwin'
    # via mlx-whisper
mlx-metal==0.29.0 ; sys_platform == 'darwin'
    # via mlx
mlx-whisper==0.4.3 ; sys_platform == 'darwin'
    # via verbatim
more-itertools==10.7.0
    # via
    #   mlx-whisper
    #   openai-whisper
mosestokenizer==1.2.1
    # via wtpsplit
mpmath==1.3.0
    # via sympy
msgpack==1.1.1
    # via librosa
multidict==6.6.4
    # via
    #   aiohttp
    #   yarl
multiprocess==0.70.16
    # via datasets
mypy-extensions==1.1.0
    # via typing-inspect
networkx==3.4.2 ; python_full_version < '3.11'
    # via torch
networkx==3.5 ; python_full_version >= '3.11'
    # via torch
numba==0.62.1
    # via
    #   librosa
    #   mlx-whisper
    #   openai-whisper
    #   resampy
numpy==2.2.6 ; python_full_version < '3.11'
    # via
    #   audio-separator
    #   ctranslate2
    #   datasets
    #   diffq
    #   diffq-fixed
    #   librosa
    #   ml-dtypes
    #   mlx-whisper
    #   numba
    #   onnx-weekly
    #   onnx2torch-py313
    #   onnxruntime
    #   openai-whisper
    #   openunmix
    #   pandas
    #   pywhispercpp
    #   resampy
    #   samplerate
    #   scikit-learn
    #   scipy
    #   skops
    #   soundfile
    #   soxr
    #   speechbrain
    #   torchvision
    #   transformers
    #   verbatim
    #   wtpsplit
numpy==2.3.5 ; python_full_version >= '3.11'
    # via
    #   audio-separator
    #   ctranslate2
    #   datasets
    #   diffq
    #   diffq-fixed
    #   librosa
    #   ml-dtypes
    #   mlx-whisper
    #   numba
    #   onnx-weekly
    #   onnx2torch-py313
    #   onnxruntime
    #   openai-whisper
    #   openunmix
    #   pandas
    #   pywhispercpp
    #   resampy
    #   samplerate
    #   scikit-learn
    #   scipy
    #   skops
    #   soundfile
    #   soxr
    #   speechbrain
    #   torchvision
    #   transformers
    #   verbatim
    #   wtpsplit
nvidia-cublas-cu12==12.8.4.1 ; platform_machine == 'x86_64' and sys_platform == 'linux'
    # via
    #   nvidia-cudnn-cu12
    #   nvidia-cusolver-cu12
    #   torch
nvidia-cuda-cupti-cu12==12.8.90 ; platform_machine == 'x86_64' and sys_platform == 'linux'
    # via torch
nvidia-cuda-nvrtc-cu12==12.8.93 ; platform_machine == 'x86_64' and sys_platform == 'linux'
    # via torch
nvidia-cuda-runtime-cu12==12.8.90 ; platform_machine == 'x86_64' and sys_platform == 'linux'
    # via torch
nvidia-cudnn-cu12==9.10.2.21 ; platform_machine == 'x86_64' and sys_platform == 'linux'
    # via torch
nvidia-cufft-cu12==11.3.3.83 ; platform_machine == 'x86_64' and sys_platform == 'linux'
    # via torch
nvidia-cufile-cu12==1.13.1.3 ; platform_machine == 'x86_64' and sys_platform == 'linux'
    # via torch
nvidia-curand-cu12==10.3.9.90 ; platform_machine == 'x86_64' and sys_platform == 'linux'
    # via torch
nvidia-cusolver-cu12==11.7.3.90 ; platform_machine == 'x86_64' and sys_platform == 'linux'
    # via torch
nvidia-cusparse-cu12==12.5.8.93 ; platform_machine == 'x86_64' and sys_platform == 'linux'
    # via
    #   nvidia-cusolver-cu12
    #   torch
nvidia-cusparselt-cu12==0.7.1 ; platform_machine == 'x86_64' and sys_platform == 'linux'
    # via torch
nvidia-nccl-cu12==2.27.3 ; platform_machine == 'x86_64' and sys_platform == 'linux'
    # via torch
nvidia-nvjitlink-cu12==12.8.93 ; platform_machine == 'x86_64' and sys_platform == 'linux'
    # via
    #   nvidia-cufft-cu12
    #   nvidia-cusolver-cu12
    #   nvidia-cusparse-cu12
    #   torch
nvidia-nvtx-cu12==12.8.90 ; platform_machine == 'x86_64' and sys_platform == 'linux'
    # via torch
omegaconf==2.3.0
    # via dora-search
onnx-weekly==1.21.0.dev20251124
    # via
    #   audio-separator
    #   onnx2torch-py313
onnx2torch-py313==1.6.0
    # via audio-separator
onnxruntime==1.19.2
    # via
    #   faster-whisper
    #   silero-vad
    #   verbatim
openai==1.102.0
    # via verbatim
openai-whisper==20250625
    # via verbatim
openfile==0.0.7
    # via mosestokenizer
openunmix==1.3.0
    # via demucs
packaging==25.0
    # via
    #   adapters
    #   datasets
    #   huggingface-hub
    #   lazy-loader
    #   marshmallow
    #   onnxruntime
    #   pooch
    #   pytest
    #   skops
    #   speechbrain
    #   transformers
pandas==2.3.2
    # via
    #   datasets
    #   wtpsplit
pillow==10.4.0
    # via
    #   torchvision
    #   verbatim
platformdirs==4.4.0
    # via
    #   pooch
    #   pylint
    #   pywhispercpp
pluggy==1.6.0
    # via pytest
pooch==1.8.2
    # via librosa
prettytable==3.16.0
    # via skops
propcache==0.3.2
    # via
    #   aiohttp
    #   yarl
protobuf==6.32.0
    # via
    #   onnx-weekly
    #   onnxruntime
pyarrow==21.0.0
    # via datasets
pyaudio==0.2.14
    # via verbatim
pycparser==2.22
    # via cffi
pydantic==2.11.7
    # via openai
pydantic-core==2.33.2
    # via pydantic
pydub==0.25.1
    # via
    #   audio-separator
    #   verbatim
pygments==2.19.2
    # via pytest
pylint==3.3.8
pyreadline3==3.5.4 ; sys_platform == 'win32'
    # via humanfriendly
pytest==8.4.1
python-dateutil==2.9.0.post0
    # via pandas
python-docx==1.2.0
    # via verbatim
python-dotenv==1.1.1
    # via verbatim
pytz==2025.2
    # via pandas
pywhispercpp==1.3.3
    # via verbatim
pyyaml==6.0.2
    # via
    #   audio-separator
    #   ctranslate2
    #   datasets
    #   demucs
    #   huggingface-hub
    #   hyperpyyaml
    #   ml-collections
    #   omegaconf
    #   transformers
    #   verbatim
regex==2025.7.34
    # via
    #   tiktoken
    #   transformers
requests==2.32.5
    # via
    #   audio-separator
    #   datasets
    #   huggingface-hub
    #   pooch
    #   pywhispercpp
    #   tiktoken
    #   transformers
resampy==0.4.3
    # via audio-separator
retrying==1.4.2
    # via dora-search
rotary-embedding-torch==0.6.5
    # via audio-separator
ruamel-yaml==0.18.15
    # via hyperpyyaml
ruamel-yaml-clib==0.2.12 ; platform_python_implementation == 'CPython'
    # via ruamel-yaml
ruff==0.12.11
safetensors==0.6.2
    # via transformers
samplerate==0.1.0
    # via audio-separator
scikit-learn==1.7.1
    # via
    #   librosa
    #   skops
    #   wtpsplit
scipy==1.15.3 ; python_full_version < '3.11'
    # via
    #   audio-separator
    #   librosa
    #   mlx-whisper
    #   scikit-learn
    #   skops
    #   speechbrain
scipy==1.16.1 ; python_full_version >= '3.11'
    # via
    #   audio-separator
    #   librosa
    #   mlx-whisper
    #   scikit-learn
    #   skops
    #   speechbrain
sentencepiece==0.2.1
    # via speechbrain
setuptools==80.9.0
    # via
    #   ctranslate2
    #   torch
    #   triton
silero-vad==6.0.0
    # via verbatim
six==1.17.0
    # via
    #   audio-separator
    #   python-dateutil
skops==0.13.0
    # via wtpsplit
sniffio==1.3.1
    # via
    #   anyio
    #   openai
sounddevice==0.5.2
    # via verbatim
soundfile==0.13.1
    # via
    #   audio-separator
    #   librosa
    #   verbatim
soxr==0.5.0.post1
    # via librosa
speechbrain==1.0.3
    # via verbatim
submitit==1.5.3
    # via dora-search
sympy==1.14.0
    # via
    #   onnxruntime
    #   torch
termcolor==3.1.0
    # via verbatim
threadpoolctl==3.6.0
    # via scikit-learn
tiktoken==0.11.0
    # via
    #   mlx-whisper
    #   openai-whisper
tokenizers==0.21.4
    # via
    #   faster-whisper
    #   transformers
tomli==2.2.1 ; python_full_version < '3.11'
    # via
    #   pylint
    #   pytest
tomlkit==0.13.3
    # via pylint
toolwrapper==2.1.0
    # via mosestokenizer
torch==2.8.0
    # via
    #   audio-separator
    #   demucs
    #   diffq
    #   diffq-fixed
    #   dora-search
    #   julius
    #   mlx-whisper
    #   onnx2torch-py313
    #   openai-whisper
    #   openunmix
    #   rotary-embedding-torch
    #   silero-vad
    #   speechbrain
    #   torchaudio
    #   torchvision
    #   verbatim
torchaudio==2.8.0
    # via
    #   demucs
    #   openunmix
    #   silero-vad
    #   speechbrain
    #   verbatim
torchvision==0.23.0
    # via onnx2torch-py313
tqdm==4.67.1
    # via
    #   audio-separator
    #   datasets
    #   demucs
    #   faster-whisper
    #   huggingface-hub
    #   mlx-whisper
    #   openai
    #   openai-whisper
    #   openunmix
    #   pywhispercpp
    #   speechbrain
    #   transformers
    #   wtpsplit
transformers==4.51.3
    # via
    #   adapters
    #   wtpsplit
treetable==0.2.5
    # via dora-search
triton==3.4.0 ; (platform_machine == 'x86_64' and sys_platform == 'linux') or sys_platform == 'linux2'
    # via
    #   openai-whisper
    #   torch
typing-extensions==4.15.0
    # via
    #   aiosignal
    #   anyio
    #   astroid
    #   exceptiongroup
    #   huggingface-hub
    #   librosa
    #   multidict
    #   onnx-weekly
    #   openai
    #   pydantic
    #   pydantic-core
    #   python-docx
    #   submitit
    #   torch
    #   typing-inspect
    #   typing-inspection
typing-inspect==0.9.0
    # via dataclasses-json
typing-inspection==0.4.1
    # via pydantic
tzdata==2025.2
    # via pandas
uctools==1.3.0
    # via mosestokenizer
urllib3==2.5.0
    # via requests
wcwidth==0.2.13
    # via prettytable
wheel==0.45.1
    # via verbatim
word-levenshtein==0.0.3
    # via verbatim
wtpsplit==2.1.6
    # via verbatim
xxhash==3.5.0
    # via datasets
yarl==1.20.1
    # via aiohttp
